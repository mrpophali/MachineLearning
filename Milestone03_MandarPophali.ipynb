{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">Milestone 3:  Diaper Manufacturing quality control using Neural Network</font>\n",
    "# <font color=\"blue\">Author: Mandar Pophali</font>\n",
    "### <font color=\"blue\">Date: 8th Dec 2019</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Description:\n",
    "\n",
    "For the diaper manufacturing data provided in UCI repository, plan following \n",
    "\n",
    "**Milestone1**\n",
    "1. Read and merge data\n",
    "2. Clean and prepare data \n",
    "3. Visually explore data\n",
    "4. Handle class imbalance problem\n",
    "5. Apply feature selection techniques to reduce dimensionality of data\n",
    "\n",
    "**Milestone3**\n",
    "6. Split prepared data from Milestone 1 into training and testing\n",
    "7. Build a simple neural networks model\n",
    "8. Build a DNN model\n",
    "9. Build a RNN model\n",
    "10. Summarize your findings with examples.  Explain what the manufacturer should focus on to optimize the diaper manufacturing process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# for hyperparameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load secom dataset \n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data\"\n",
    "#Names the columns as Feature<number>\n",
    "\n",
    "names = [\"feature\" + str(x) for x in range(1, 591)]\n",
    "secom_var = pd.read_csv(url, sep=\" \", names=names, na_values = \"NaN\") \n",
    "\n",
    "# use classification as output along with date\n",
    "url_l = \"https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data\"\n",
    "secom_labels = pd.read_csv(url_l,sep=\" \",names = [\"classification\",\"date\"],parse_dates = [\"date\"],na_values = \"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the label and datasets\n",
    "dia_merged = pd.merge(secom_var, secom_labels,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature587</th>\n",
       "      <th>feature588</th>\n",
       "      <th>feature589</th>\n",
       "      <th>feature590</th>\n",
       "      <th>classification</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>2899.41</td>\n",
       "      <td>2464.36</td>\n",
       "      <td>2179.7333</td>\n",
       "      <td>3085.3781</td>\n",
       "      <td>1.4843</td>\n",
       "      <td>100.0</td>\n",
       "      <td>82.2467</td>\n",
       "      <td>0.1248</td>\n",
       "      <td>1.3424</td>\n",
       "      <td>-0.0045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>2.8669</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-16 15:13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>3052.31</td>\n",
       "      <td>2522.55</td>\n",
       "      <td>2198.5667</td>\n",
       "      <td>1124.6595</td>\n",
       "      <td>0.8763</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4689</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>-0.0061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>2.6238</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>203.1720</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-16 20:49:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>2978.81</td>\n",
       "      <td>2379.78</td>\n",
       "      <td>2206.3000</td>\n",
       "      <td>1110.4967</td>\n",
       "      <td>0.8236</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.4122</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>3.0590</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>43.5231</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-17 05:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>2894.92</td>\n",
       "      <td>2532.01</td>\n",
       "      <td>2177.0333</td>\n",
       "      <td>1183.7287</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.7978</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>1.4622</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5004</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>3.5662</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>93.4941</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-17 06:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>2944.92</td>\n",
       "      <td>2450.76</td>\n",
       "      <td>2195.4444</td>\n",
       "      <td>2914.1792</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.1011</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4987</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>3.6275</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>137.7844</td>\n",
       "      <td>-1</td>\n",
       "      <td>2008-10-17 06:07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 592 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature1  feature2   feature3   feature4  feature5  feature6  feature7  \\\n",
       "1562   2899.41   2464.36  2179.7333  3085.3781    1.4843     100.0   82.2467   \n",
       "1563   3052.31   2522.55  2198.5667  1124.6595    0.8763     100.0   98.4689   \n",
       "1564   2978.81   2379.78  2206.3000  1110.4967    0.8236     100.0   99.4122   \n",
       "1565   2894.92   2532.01  2177.0333  1183.7287    1.5726     100.0   98.7978   \n",
       "1566   2944.92   2450.76  2195.4444  2914.1792    1.5978     100.0   85.1011   \n",
       "\n",
       "      feature8  feature9  feature10  ...  feature583  feature584  feature585  \\\n",
       "1562    0.1248    1.3424    -0.0045  ...      0.4988      0.0143      0.0039   \n",
       "1563    0.1205    1.4333    -0.0061  ...      0.4975      0.0131      0.0036   \n",
       "1564    0.1208       NaN        NaN  ...      0.4987      0.0153      0.0041   \n",
       "1565    0.1213    1.4622    -0.0072  ...      0.5004      0.0178      0.0038   \n",
       "1566    0.1235       NaN        NaN  ...      0.4987      0.0181      0.0040   \n",
       "\n",
       "      feature586  feature587  feature588  feature589  feature590  \\\n",
       "1562      2.8669      0.0068      0.0138      0.0047    203.1720   \n",
       "1563      2.6238      0.0068      0.0138      0.0047    203.1720   \n",
       "1564      3.0590      0.0197      0.0086      0.0025     43.5231   \n",
       "1565      3.5662      0.0262      0.0245      0.0075     93.4941   \n",
       "1566      3.6275      0.0117      0.0162      0.0045    137.7844   \n",
       "\n",
       "      classification                date  \n",
       "1562              -1 2008-10-16 15:13:00  \n",
       "1563              -1 2008-10-16 20:49:00  \n",
       "1564              -1 2008-10-17 05:26:00  \n",
       "1565              -1 2008-10-17 06:01:00  \n",
       "1566              -1 2008-10-17 06:07:00  \n",
       "\n",
       "[5 rows x 592 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dia_merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 592)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dia_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1463\n",
       " 1     104\n",
       "Name: classification, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dia_merged.classification.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial summary of dataset**\n",
    "1. The dataset contains 590 sensor data for manufacturing of diapers. There are total 1567 data which represents machine runs from 19th July 2008 to 17th Oct 2008 (3 months)\n",
    "2. Classification feature is the dependant feature. '-1' represents successfull run while '1' represents failure\n",
    "3. Output class has imbalanced data (14:1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace dependant feature as 1=Failure and 0=success\n",
    "dia_merged.classification = dia_merged.classification.replace(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1463\n",
       "1     104\n",
       "Name: classification, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dia_merged.classification.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets convert all features to float/numberic\n",
    "dia_df = dia_merged.apply(pd.to_numeric,errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check the missing values for each feature in \n",
    "\n",
    "data_missing= dia_df.isna().sum().sort_values(ascending=False)\n",
    "data_missing.hist(bins=100)\n",
    "plt.title(\"Distribution of missing values\")\n",
    "plt.xlabel(\"No. of missing values in a column\")\n",
    "plt.ylabel(\"Columns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets remove all columns where there are more than 800 values missing. Its no use to fill them out with any data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 564)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dia_df.dropna(axis='columns',thresh=800,inplace=True)\n",
    "dia_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From 590 features, it has come down to 564. Now lets review how many columns have same values or zero std deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count features having very low std deviation\n",
    "dia_df.loc[:, dia_df.std() <= 0.001].nunique().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 438)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop all columns having similar values or low std deviation \n",
    "dia_new = dia_df.loc[:, dia_df.std() > 0.001]\n",
    "dia_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The total features remaining are now 438 which is 126 less than 564 in step above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature587</th>\n",
       "      <th>feature588</th>\n",
       "      <th>feature589</th>\n",
       "      <th>feature590</th>\n",
       "      <th>classification</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1561.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>1553.000000</td>\n",
       "      <td>1553.000000</td>\n",
       "      <td>1553.000000</td>\n",
       "      <td>1553.000000</td>\n",
       "      <td>1558.000000</td>\n",
       "      <td>1565.000000</td>\n",
       "      <td>1565.000000</td>\n",
       "      <td>1565.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>1566.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "      <td>1.567000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3014.452896</td>\n",
       "      <td>2495.850231</td>\n",
       "      <td>2200.547318</td>\n",
       "      <td>1396.376627</td>\n",
       "      <td>4.197013</td>\n",
       "      <td>101.112908</td>\n",
       "      <td>0.121822</td>\n",
       "      <td>1.462862</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500096</td>\n",
       "      <td>0.015318</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>3.067826</td>\n",
       "      <td>0.021458</td>\n",
       "      <td>0.016475</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>99.670066</td>\n",
       "      <td>0.066369</td>\n",
       "      <td>1.217454e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>73.621787</td>\n",
       "      <td>80.407705</td>\n",
       "      <td>29.513152</td>\n",
       "      <td>441.691640</td>\n",
       "      <td>56.355540</td>\n",
       "      <td>6.237214</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>0.073897</td>\n",
       "      <td>0.015116</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.017180</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>3.578033</td>\n",
       "      <td>0.012358</td>\n",
       "      <td>0.008808</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>93.891919</td>\n",
       "      <td>0.249005</td>\n",
       "      <td>7.023985e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2743.240000</td>\n",
       "      <td>2158.750000</td>\n",
       "      <td>2060.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681500</td>\n",
       "      <td>82.131100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.191000</td>\n",
       "      <td>-0.053400</td>\n",
       "      <td>-0.034900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.477800</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.197500</td>\n",
       "      <td>-0.016900</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.199758e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2966.260000</td>\n",
       "      <td>2452.247500</td>\n",
       "      <td>2181.044400</td>\n",
       "      <td>1081.875800</td>\n",
       "      <td>1.017700</td>\n",
       "      <td>97.920000</td>\n",
       "      <td>0.121100</td>\n",
       "      <td>1.411200</td>\n",
       "      <td>-0.010800</td>\n",
       "      <td>-0.005600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497900</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>2.306500</td>\n",
       "      <td>0.013425</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>44.368600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.215618e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3011.490000</td>\n",
       "      <td>2499.405000</td>\n",
       "      <td>2201.066700</td>\n",
       "      <td>1285.214400</td>\n",
       "      <td>1.316800</td>\n",
       "      <td>101.512200</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>1.461600</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>2.757650</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>71.900500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.219497e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3056.650000</td>\n",
       "      <td>2538.822500</td>\n",
       "      <td>2218.055500</td>\n",
       "      <td>1591.223500</td>\n",
       "      <td>1.525700</td>\n",
       "      <td>104.586700</td>\n",
       "      <td>0.123800</td>\n",
       "      <td>1.516900</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502375</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>3.295175</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>114.749700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.222082e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3356.350000</td>\n",
       "      <td>2846.440000</td>\n",
       "      <td>2315.266700</td>\n",
       "      <td>3715.041700</td>\n",
       "      <td>1114.536600</td>\n",
       "      <td>129.252200</td>\n",
       "      <td>0.128600</td>\n",
       "      <td>1.656400</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509800</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>99.303200</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.028600</td>\n",
       "      <td>737.304800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.228935e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 438 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature1     feature2     feature3     feature4     feature5  \\\n",
       "count  1561.000000  1560.000000  1553.000000  1553.000000  1553.000000   \n",
       "mean   3014.452896  2495.850231  2200.547318  1396.376627     4.197013   \n",
       "std      73.621787    80.407705    29.513152   441.691640    56.355540   \n",
       "min    2743.240000  2158.750000  2060.660000     0.000000     0.681500   \n",
       "25%    2966.260000  2452.247500  2181.044400  1081.875800     1.017700   \n",
       "50%    3011.490000  2499.405000  2201.066700  1285.214400     1.316800   \n",
       "75%    3056.650000  2538.822500  2218.055500  1591.223500     1.525700   \n",
       "max    3356.350000  2846.440000  2315.266700  3715.041700  1114.536600   \n",
       "\n",
       "          feature7     feature8     feature9    feature10    feature11  ...  \\\n",
       "count  1553.000000  1558.000000  1565.000000  1565.000000  1565.000000  ...   \n",
       "mean    101.112908     0.121822     1.462862    -0.000841     0.000146  ...   \n",
       "std       6.237214     0.008961     0.073897     0.015116     0.009302  ...   \n",
       "min      82.131100     0.000000     1.191000    -0.053400    -0.034900  ...   \n",
       "25%      97.920000     0.121100     1.411200    -0.010800    -0.005600  ...   \n",
       "50%     101.512200     0.122400     1.461600    -0.001300     0.000400  ...   \n",
       "75%     104.586700     0.123800     1.516900     0.008400     0.005900  ...   \n",
       "max     129.252200     0.128600     1.656400     0.074900     0.053000  ...   \n",
       "\n",
       "        feature583   feature584   feature585   feature586   feature587  \\\n",
       "count  1566.000000  1566.000000  1566.000000  1566.000000  1566.000000   \n",
       "mean      0.500096     0.015318     0.003847     3.067826     0.021458   \n",
       "std       0.003404     0.017180     0.003720     3.578033     0.012358   \n",
       "min       0.477800     0.006000     0.001700     1.197500    -0.016900   \n",
       "25%       0.497900     0.011600     0.003100     2.306500     0.013425   \n",
       "50%       0.500200     0.013800     0.003600     2.757650     0.020500   \n",
       "75%       0.502375     0.016500     0.004100     3.295175     0.027600   \n",
       "max       0.509800     0.476600     0.104500    99.303200     0.102800   \n",
       "\n",
       "        feature588   feature589   feature590  classification          date  \n",
       "count  1566.000000  1566.000000  1566.000000     1567.000000  1.567000e+03  \n",
       "mean      0.016475     0.005283    99.670066        0.066369  1.217454e+18  \n",
       "std       0.008808     0.002867    93.891919        0.249005  7.023985e+15  \n",
       "min       0.003200     0.001000     0.000000        0.000000  1.199758e+18  \n",
       "25%       0.010600     0.003300    44.368600        0.000000  1.215618e+18  \n",
       "50%       0.014800     0.004600    71.900500        0.000000  1.219497e+18  \n",
       "75%       0.020300     0.006400   114.749700        0.000000  1.222082e+18  \n",
       "max       0.079900     0.028600   737.304800        1.000000  1.228935e+18  \n",
       "\n",
       "[8 rows x 438 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dia_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature248        715\n",
       "feature520        715\n",
       "feature386        715\n",
       "feature113        715\n",
       "feature567        273\n",
       "                 ... \n",
       "feature157          0\n",
       "feature222          0\n",
       "classification      0\n",
       "feature256          0\n",
       "date                0\n",
       "Length: 438, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values in the data\n",
    "dia_new.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 434)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#i am going to remove top 4 features which are having 715 missing values \n",
    "dia_new = dia_new.drop(['feature248','feature520','feature386','feature113'],axis=1)\n",
    "dia_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### replace missing values using experimental iterative imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=3, random_state=0)\n",
    "dia = pd.DataFrame(imp.fit_transform(dia_new),columns=dia_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date          0\n",
       "feature172    0\n",
       "feature161    0\n",
       "feature162    0\n",
       "feature163    0\n",
       "             ..\n",
       "feature392    0\n",
       "feature393    0\n",
       "feature394    0\n",
       "feature406    0\n",
       "feature1      0\n",
       "Length: 434, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values in the new dataframe to confirm\n",
    "dia.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>feature10</th>\n",
       "      <th>feature11</th>\n",
       "      <th>...</th>\n",
       "      <th>feature583</th>\n",
       "      <th>feature584</th>\n",
       "      <th>feature585</th>\n",
       "      <th>feature586</th>\n",
       "      <th>feature587</th>\n",
       "      <th>feature588</th>\n",
       "      <th>feature589</th>\n",
       "      <th>feature590</th>\n",
       "      <th>classification</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3030.93</td>\n",
       "      <td>2564.00</td>\n",
       "      <td>2187.7333</td>\n",
       "      <td>1411.1265</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>97.6133</td>\n",
       "      <td>0.1242</td>\n",
       "      <td>1.5005</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5005</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>2.3630</td>\n",
       "      <td>0.023282</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>100.852593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.216468e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3095.78</td>\n",
       "      <td>2465.14</td>\n",
       "      <td>2230.4222</td>\n",
       "      <td>1463.6606</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>102.3433</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>1.4966</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.0148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>4.4447</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>208.204500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.216471e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2932.61</td>\n",
       "      <td>2559.94</td>\n",
       "      <td>2186.4111</td>\n",
       "      <td>1698.0172</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>95.4878</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4958</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>3.1745</td>\n",
       "      <td>0.058400</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>82.860200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.216473e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2988.72</td>\n",
       "      <td>2479.90</td>\n",
       "      <td>2199.0333</td>\n",
       "      <td>909.7926</td>\n",
       "      <td>1.3204</td>\n",
       "      <td>104.2367</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>1.4882</td>\n",
       "      <td>-0.0124</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4990</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2.0544</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>73.843200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.216479e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032.24</td>\n",
       "      <td>2502.87</td>\n",
       "      <td>2233.3667</td>\n",
       "      <td>1326.5200</td>\n",
       "      <td>1.5334</td>\n",
       "      <td>100.3967</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>1.5031</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.4766</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>99.3032</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>73.843200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.216481e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature1  feature2   feature3   feature4  feature5  feature7  feature8  \\\n",
       "0   3030.93   2564.00  2187.7333  1411.1265    1.3602   97.6133    0.1242   \n",
       "1   3095.78   2465.14  2230.4222  1463.6606    0.8294  102.3433    0.1247   \n",
       "2   2932.61   2559.94  2186.4111  1698.0172    1.5102   95.4878    0.1241   \n",
       "3   2988.72   2479.90  2199.0333   909.7926    1.3204  104.2367    0.1217   \n",
       "4   3032.24   2502.87  2233.3667  1326.5200    1.5334  100.3967    0.1235   \n",
       "\n",
       "   feature9  feature10  feature11  ...  feature583  feature584  feature585  \\\n",
       "0    1.5005     0.0162    -0.0034  ...      0.5005      0.0118      0.0035   \n",
       "1    1.4966    -0.0005    -0.0148  ...      0.5019      0.0223      0.0055   \n",
       "2    1.4436     0.0041     0.0013  ...      0.4958      0.0157      0.0039   \n",
       "3    1.4882    -0.0124    -0.0033  ...      0.4990      0.0103      0.0025   \n",
       "4    1.5031    -0.0031    -0.0072  ...      0.4800      0.4766      0.1045   \n",
       "\n",
       "   feature586  feature587  feature588  feature589  feature590  classification  \\\n",
       "0      2.3630    0.023282    0.006882    0.000209  100.852593             0.0   \n",
       "1      4.4447    0.009600    0.020100    0.006000  208.204500             0.0   \n",
       "2      3.1745    0.058400    0.048400    0.014800   82.860200             1.0   \n",
       "3      2.0544    0.020200    0.014900    0.004400   73.843200             0.0   \n",
       "4     99.3032    0.020200    0.014900    0.004400   73.843200             0.0   \n",
       "\n",
       "           date  \n",
       "0  1.216468e+18  \n",
       "1  1.216471e+18  \n",
       "2  1.216473e+18  \n",
       "3  1.216479e+18  \n",
       "4  1.216481e+18  \n",
       "\n",
       "[5 rows x 434 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In case of imbalaced data, random forests or decision tree based algorithms may peform better. Lets use random Forests classifier and get feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate x and y in dataset \n",
    "y = dia['classification']\n",
    "X = dia.drop(['classification','date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data in train and test\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=7, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=7)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Rank:\n",
      "  1 column   59  0.0119\n",
      "  2 column   54  0.0110\n",
      "  3 column   60  0.0080\n",
      "  4 column  408  0.0073\n",
      "  5 column  314  0.0069\n",
      "  6 column   89  0.0068\n",
      "  7 column   38  0.0067\n",
      "  8 column  205  0.0064\n",
      "  9 column  132  0.0064\n",
      " 10 column   36  0.0058\n",
      " 11 column  355  0.0058\n",
      " 12 column  269  0.0057\n",
      " 13 column  329  0.0056\n",
      " 14 column   23  0.0053\n",
      " 15 column   65  0.0052\n",
      "\n",
      "\n",
      "428 column  177  0.0000\n",
      "429 column  356  0.0000\n",
      "430 column  174  0.0000\n",
      "431 column  265  0.0000\n",
      "432 column  268  0.0000\n",
      "The number of features better than average is: 154\n"
     ]
    }
   ],
   "source": [
    "# displaying features and their rank\n",
    "\n",
    "importance = rf.feature_importances_\n",
    "ranked_indices = np.argsort(importance)[::-1]\n",
    "\n",
    "print(\"Feature Rank:\")\n",
    "for i in range(15):\n",
    "    print(\"{0:3d} column  {1:3d}  {2:6.4f}\".format(i+1, ranked_indices[i], importance[ranked_indices[i]]))\n",
    "print (\"\\n\")\n",
    "for i in range(len(importance)-5,len(importance)):\n",
    "    print(\"{0:3d} column  {1:3d}  {2:6.4f}\".format(i+1, ranked_indices[i], importance[ranked_indices[i]]))\n",
    "\n",
    "navg = 0\n",
    "for i in range(len(importance)):    \n",
    "    if importance[ranked_indices[i]] > np.average(rf.feature_importances_):\n",
    "        navg = navg+1\n",
    "print('The number of features better than average is: {}'.format(navg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of importance vs the number of features\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(len(importance)), importance[ranked_indices[:]])\n",
    "plt.axvline(15, color='magenta', linestyle='dashdot', label='n=15')\n",
    "plt.axvline(40, color='orange', linestyle='dashed', label='n=40')\n",
    "plt.axvline(65, color='turquoise', linestyle='dashdot', label='n=65')\n",
    "plt.axvline(100, color='red', linestyle='dotted', label='n=100')\n",
    "plt.text(15, 0.002, 'n=15', rotation='vertical')\n",
    "plt.text(40, 0.008, 'n=40', rotation='vertical')\n",
    "plt.text(65, 0.011, 'n=65', rotation='vertical')\n",
    "plt.text(100, 0.014, 'n=100', rotation='vertical')\n",
    "plt.title('Importance vs feature rank')\n",
    "plt.xlabel('feature rank')\n",
    "plt.ylabel('importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From this plot, we see points of inflection around the 15, 40, 65 and 100 mark. The 50 percentile mark is at 148 so these are reduced feature sets, much smaller than the 434 features we have after cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature65',\n",
       " 'feature60',\n",
       " 'feature66',\n",
       " 'feature563',\n",
       " 'feature427',\n",
       " 'feature104',\n",
       " 'feature41',\n",
       " 'feature268',\n",
       " 'feature154',\n",
       " 'feature39',\n",
       " 'feature478',\n",
       " 'feature349',\n",
       " 'feature442',\n",
       " 'feature26',\n",
       " 'feature72',\n",
       " 'feature426',\n",
       " 'feature342',\n",
       " 'feature17',\n",
       " 'feature27',\n",
       " 'feature211',\n",
       " 'feature206',\n",
       " 'feature78',\n",
       " 'feature302',\n",
       " 'feature133',\n",
       " 'feature22',\n",
       " 'feature100',\n",
       " 'feature3',\n",
       " 'feature153',\n",
       " 'feature288',\n",
       " 'feature540',\n",
       " 'feature52',\n",
       " 'feature64',\n",
       " 'feature575',\n",
       " 'feature353',\n",
       " 'feature167',\n",
       " 'feature332',\n",
       " 'feature212',\n",
       " 'feature552',\n",
       " 'feature511',\n",
       " 'feature430',\n",
       " 'feature438',\n",
       " 'feature103',\n",
       " 'feature122',\n",
       " 'feature351',\n",
       " 'feature1',\n",
       " 'feature436',\n",
       " 'feature289',\n",
       " 'feature82',\n",
       " 'feature568',\n",
       " 'feature551',\n",
       " 'feature495',\n",
       " 'feature562',\n",
       " 'feature555',\n",
       " 'feature124',\n",
       " 'feature476',\n",
       " 'feature63',\n",
       " 'feature558',\n",
       " 'feature424',\n",
       " 'feature213',\n",
       " 'feature300',\n",
       " 'feature157',\n",
       " 'feature583',\n",
       " 'feature334',\n",
       " 'feature360',\n",
       " 'feature89',\n",
       " 'feature171',\n",
       " 'feature461',\n",
       " 'feature165',\n",
       " 'feature240',\n",
       " 'feature222',\n",
       " 'feature31',\n",
       " 'feature524',\n",
       " 'feature76',\n",
       " 'feature585',\n",
       " 'feature28',\n",
       " 'feature350',\n",
       " 'feature68',\n",
       " 'feature23',\n",
       " 'feature494',\n",
       " 'feature121',\n",
       " 'feature477',\n",
       " 'feature169',\n",
       " 'feature155',\n",
       " 'feature34',\n",
       " 'feature125',\n",
       " 'feature120',\n",
       " 'feature437',\n",
       " 'feature498',\n",
       " 'feature434',\n",
       " 'feature46',\n",
       " 'feature62',\n",
       " 'feature118',\n",
       " 'feature363',\n",
       " 'feature201',\n",
       " 'feature364',\n",
       " 'feature204',\n",
       " 'feature189',\n",
       " 'feature588',\n",
       " 'feature338',\n",
       " 'feature474',\n",
       " 'feature574',\n",
       " 'feature557',\n",
       " 'feature355',\n",
       " 'feature71',\n",
       " 'feature215',\n",
       " 'feature108',\n",
       " 'feature501',\n",
       " 'feature198',\n",
       " 'feature170',\n",
       " 'feature49',\n",
       " 'feature217',\n",
       " 'feature84',\n",
       " 'feature13',\n",
       " 'feature296',\n",
       " 'feature299',\n",
       " 'feature94',\n",
       " 'feature572',\n",
       " 'feature421',\n",
       " 'feature340',\n",
       " 'feature577',\n",
       " 'feature570',\n",
       " 'feature148',\n",
       " 'feature79',\n",
       " 'feature139',\n",
       " 'feature226',\n",
       " 'feature584',\n",
       " 'feature366',\n",
       " 'feature304',\n",
       " 'feature578',\n",
       " 'feature83',\n",
       " 'feature422',\n",
       " 'feature576',\n",
       " 'feature161',\n",
       " 'feature489',\n",
       " 'feature12',\n",
       " 'feature560',\n",
       " 'feature223',\n",
       " 'feature292',\n",
       " 'feature431',\n",
       " 'feature432',\n",
       " 'feature357',\n",
       " 'feature197',\n",
       " 'feature283',\n",
       " 'feature325',\n",
       " 'feature11',\n",
       " 'feature439',\n",
       " 'feature196',\n",
       " 'feature333']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select first 148 features for next analysis\n",
    "dia_importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "selected = list(dia_importances.nlargest(148).index)\n",
    "selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create final DataFrame with 148 features\n",
    "dia_final = dia[selected].join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1567, 149)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dia_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dia_final.iloc[:,:148]\n",
    "y = dia_final.iloc[:,148]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U imbalanced-learn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as previously noted, the dataset is highly imbalanced (13:1). I am proposing to use SMOTE to increase percentage of \n",
    "#minority class in dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#create SMOTE object\n",
    "sm = SMOTE(sampling_strategy=1.0,k_neighbors=3,random_state=1)\n",
    "X_sm, y_sm = sm.fit_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([1463, 1463], dtype=int64))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#both classes are now equally populated \n",
    "np.unique(y_sm,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train:  (2340, 148)\n",
      "shape of x_test:  (586, 148)\n",
      "shape of y_train:  (2340,)\n",
      "shape of y_test:  (586,)\n"
     ]
    }
   ],
   "source": [
    "# splitting them into train test and split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size = 0.2, random_state = 1)\n",
    "\n",
    "# gettiing the shapes\n",
    "print(\"shape of x_train: \", x_train.shape)\n",
    "print(\"shape of x_test: \", x_test.shape)\n",
    "print(\"shape of y_train: \", y_train.shape)\n",
    "print(\"shape of y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets scale the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#creating a standard scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#scale the independant datasets\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tf = y_train.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 100, 100, 100, 100, 100, 100, 100, 100),\n",
       "              learning_rate='constant', learning_rate_init=0.001, max_fun=15000,\n",
       "              max_iter=500, momentum=0.9, n_iter_no_change=10,\n",
       "              nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "              shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(activation = 'relu',solver= 'adam',alpha= 0.001, learning_rate='constant',momentum= 0.9,\n",
    "                    hidden_layer_sizes=(100,100,100,100,100,100,100,100,100), max_iter=500,early_stopping=True)\n",
    "\n",
    "mlp.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[293   7]\n",
      " [  2 284]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98       300\n",
      "         1.0       0.98      0.99      0.98       286\n",
      "\n",
      "    accuracy                           0.98       586\n",
      "   macro avg       0.98      0.98      0.98       586\n",
      "weighted avg       0.98      0.98      0.98       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets apply random search to optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import itertools \n",
    "\n",
    "parameters = {'solver': ['sgd','adam'], 'activation': ['tanh','relu'],'learning_rate': ['adaptive','constant'],'hidden_layer_sizes':[x for x in itertools.product((10,50,100),repeat=9)]}\n",
    "clf_grid = RandomizedSearchCV(MLPClassifier(max_iter=500,early_stopping=True), parameters, cv=12, scoring='f1',n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=12, error_score=nan,\n",
       "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                           batch_size='auto', beta_1=0.9,\n",
       "                                           beta_2=0.999, early_stopping=True,\n",
       "                                           epsilon=1e-08,\n",
       "                                           hidden_layer_sizes=(100,),\n",
       "                                           learning_rate='constant',\n",
       "                                           learning_rate_init=0.001,\n",
       "                                           max_fun=15000, max_iter=500,\n",
       "                                           momentum=0.9, n_iter_no_change=10,\n",
       "                                           nesterovs_momentum=True, power_t=0.5,\n",
       "                                           random...\n",
       "                                                               (10, 10, 10, 10,\n",
       "                                                                10, 10, 100,\n",
       "                                                                100, 10),\n",
       "                                                               (10, 10, 10, 10,\n",
       "                                                                10, 10, 100,\n",
       "                                                                100, 50),\n",
       "                                                               (10, 10, 10, 10,\n",
       "                                                                10, 10, 100,\n",
       "                                                                100, 100),\n",
       "                                                               (10, 10, 10, 10,\n",
       "                                                                10, 50, 10, 10,\n",
       "                                                                10),\n",
       "                                                               (10, 10, 10, 10,\n",
       "                                                                10, 50, 10, 10,\n",
       "                                                                50),\n",
       "                                                               (10, 10, 10, 10,\n",
       "                                                                10, 50, 10, 10,\n",
       "                                                                100), ...],\n",
       "                                        'learning_rate': ['adaptive',\n",
       "                                                          'constant'],\n",
       "                                        'solver': ['sgd', 'adam']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 50, 50, 50, 10, 50, 50, 100, 10),\n",
       "              learning_rate='adaptive', learning_rate_init=0.001, max_fun=15000,\n",
       "              max_iter=500, momentum=0.9, n_iter_no_change=10,\n",
       "              nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "              shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best parameter values\n",
    "clf_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "Classification report with gridCV optimzation\n",
      "-----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.98       300\n",
      "         1.0       0.97      1.00      0.98       286\n",
      "\n",
      "    accuracy                           0.98       586\n",
      "   macro avg       0.98      0.98      0.98       586\n",
      "weighted avg       0.98      0.98      0.98       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-'*53)\n",
    "print('Classification report with gridCV optimzation')\n",
    "print('-'*53)\n",
    "print(classification_report(y_test,clf_grid.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>292</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual     0.0  1.0\n",
       "Predicted          \n",
       "0.0        292    8\n",
       "1.0          1  285"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's plot the confusion matrix\n",
    "cm1 = pd.DataFrame(index = clf_grid.best_estimator_.classes_, \n",
    "                   columns = clf_grid.best_estimator_.classes_,\n",
    "                   data = confusion_matrix(y_test,clf_grid.predict(x_test)))\n",
    "cm1.columns.name = 'Actual'\n",
    "cm1.index.name = 'Predicted'\n",
    "cm1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep neural network using tensorflow 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to setting random_state in sklearn, but does so more broadly\n",
    "tf.compat.v1.random.set_random_seed(7299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate sequencial object\n",
    "tfclf = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets add 9 hidden layers of 20 units each\n",
    "tfclf.add(layers.Dense(148, activation='relu',input_dim=148))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also have to add the output layer\n",
    "tfclf.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick an optimizer\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.01, beta_1 = 0.1, beta_2 = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "# the metrics parameter is just for reporting\n",
    "tfclf.compile(optimizer = optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(x_test) \n",
    "#y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2340 samples\n",
      "Epoch 1/10\n",
      "2340/2340 [==============================] - 4s 2ms/sample - loss: 0.6970 - accuracy: 0.4868\n",
      "Epoch 2/10\n",
      "2340/2340 [==============================] - 1s 245us/sample - loss: 0.6948 - accuracy: 0.4970\n",
      "Epoch 3/10\n",
      "2340/2340 [==============================] - 0s 161us/sample - loss: 0.6957 - accuracy: 0.4902\n",
      "Epoch 4/10\n",
      "2340/2340 [==============================] - 1s 269us/sample - loss: 0.6939 - accuracy: 0.5038\n",
      "Epoch 5/10\n",
      "2340/2340 [==============================] - 0s 153us/sample - loss: 0.6940 - accuracy: 0.5004\n",
      "Epoch 6/10\n",
      "2340/2340 [==============================] - 0s 161us/sample - loss: 0.6936 - accuracy: 0.4987\n",
      "Epoch 7/10\n",
      "2340/2340 [==============================] - 0s 153us/sample - loss: 0.6940 - accuracy: 0.4902\n",
      "Epoch 8/10\n",
      "2340/2340 [==============================] - 0s 161us/sample - loss: 0.6937 - accuracy: 0.4962\n",
      "Epoch 9/10\n",
      "2340/2340 [==============================] - 0s 165us/sample - loss: 0.6936 - accuracy: 0.4996\n",
      "Epoch 10/10\n",
      "2340/2340 [==============================] - 0s 160us/sample - loss: 0.6935 - accuracy: 0.5030\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict\n",
    "tfclf.fit(x_train, Y_tf, epochs=10, batch_size=100, verbose=1)\n",
    "Ytfclf = tfclf.predict(x_train).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# for model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=40,min_samples_split=4,min_samples_leaf=1,random_state=987)\n",
    "dtc.fit(x_train,y_train)\n",
    "\n",
    "# predict (on both train and test sets)\n",
    "y_train_dtc = dtc.predict(x_train)\n",
    "y_test_dtc = dtc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*55)\n",
    "print('Training scores')\n",
    "print('-'*55)\n",
    "print(classification_report(y_train, y_train_dtc))\n",
    "print()\n",
    "print('-'*55)\n",
    "print('Test scores decision tree')\n",
    "print('-'*55)\n",
    "print(classification_report(y_test, y_test_dtc))\n",
    "print('-'*55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # let's plto the confusion matrix\n",
    "    cm1 = pd.DataFrame(index = dtc.classes_, \n",
    "                       columns = dtc.classes_,\n",
    "                       data = confusion_matrix(y_test, y_test_dtc))\n",
    "    cm1.columns.name = 'Actual'\n",
    "    cm1.index.name = 'Predicted'\n",
    "    cm1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets check if we can we do better using gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'min_samples_split': [2,3,4,5], 'max_depth': [20,40,60,80],'min_samples_leaf':[1,2,3,4]}\n",
    "]\n",
    "gsCV = GridSearchCV(DecisionTreeClassifier(random_state=987),param_grid=param_grid, cv=12,scoring='recall',n_jobs=-1)\n",
    "gsCV.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the best decision tree model.  It's of class DecisionTreeClassifier\n",
    "gsCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*55)\n",
    "print('Test scores from Grid search Decision tree')\n",
    "print('-'*55)\n",
    "print(classification_report(y_test, gsCV.predict(x_test)))\n",
    "print('-'*55)\n",
    "print('Test scores decision tree')\n",
    "print('-'*55)\n",
    "print(classification_report(y_test, y_test_dtc))\n",
    "print('-'*55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is hardly any diffrence between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split = 64\n",
    "max_leaf_nodes = 64\n",
    "rfc = RandomForestClassifier(n_estimators=1000,\n",
    "                             max_leaf_nodes=max_leaf_nodes, \n",
    "                             min_samples_split=min_samples_split)\n",
    "rfc.fit(x_train, y_train)\n",
    "\n",
    "# predict (on both train and test sets)\n",
    "y_train_rfc = rfc.predict(x_train)\n",
    "y_test_rfc = rfc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*53)\n",
    "print('Random Forest with non-optimal gridCV parameters')\n",
    "print('-'*53)\n",
    "print(classification_report(y_test, y_test_rfc))\n",
    "print('-'*53)\n",
    "print('Non- Optimized Decision Tree')\n",
    "print('-'*53)\n",
    "print(classification_report(y_test,y_test_dtc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is definetely improvement as compared to decision tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the confusion matrix\n",
    "cm2 = pd.DataFrame(index = rfc.classes_, \n",
    "                   columns = rfc.classes_,\n",
    "                   data = confusion_matrix(y_test, y_test_rfc))\n",
    "cm2.columns.name = 'Actual'\n",
    "cm2.index.name = 'Predicted'\n",
    "cm2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets check if we can we do better using gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GridSearchCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-774b30853399>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;33m{\u001b[0m\u001b[1;34m'max_leaf_nodes'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m ]\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrfgsCV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'recall'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mrfgsCV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'max_leaf_nodes':[20,40,80,100],'n_estimators':[100,500,1000,10000]}\n",
    "]\n",
    "rfgsCV = GridSearchCV(RandomForestClassifier(min_samples_split=64),param_grid=param_grid, cv=24,scoring='recall',n_jobs=-1)\n",
    "rfgsCV.fit(x_train,y_train.values.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the best decision tree model.  It's of class RandomForestClassifier\n",
    "rfgsCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*53)\n",
    "print('Random Forest with non-optimal gridCV parameters')\n",
    "print('-'*53)\n",
    "print(classification_report(y_test, y_test_rfc))\n",
    "print('-'*53)\n",
    "print('Random Forest with optimal gridCV parameters')\n",
    "print('-'*53)\n",
    "print(classification_report(y_test,rfgsCV.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the confusion matrix\n",
    "cm3 = pd.DataFrame(index = rfgsCV.classes_, \n",
    "                   columns = rfgsCV.classes_,\n",
    "                   data = confusion_matrix(y_test, rfgsCV.predict(x_test)))\n",
    "cm3.columns.name = 'Actual'\n",
    "cm3.index.name = 'Predicted'\n",
    "cm3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am proposing to use svmSMOTE instead of earlier one. \n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "\n",
    "#create SMOTE object\n",
    "smv = SVMSMOTE(sampling_strategy=1.0,k_neighbors=3,random_state=1)\n",
    "X_sv, y_sv = smv.fit_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how classes are populated \n",
    "np.unique(y_sv,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting them into train test and split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X_sv, y_sv, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# gettiing the shapes\n",
    "print(\"shape of x_train1: \", x_train1.shape)\n",
    "print(\"shape of x_test1: \", x_test1.shape)\n",
    "print(\"shape of y_train1: \", y_train1.shape)\n",
    "print(\"shape of y_test1: \", y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets scale the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#creating a standard scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#scale the independant datasets\n",
    "x_train1 = scaler.fit_transform(x_train1)\n",
    "x_test1 = scaler.transform(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfSVC = SVC(kernel='poly',degree=3,C=10,random_state=8,gamma='auto')\n",
    "clfSVC.fit(x_train1, y_train1)\n",
    "\n",
    "# predict (on both train and test sets)\n",
    "y_train_svc = clfSVC.predict(x_train1)\n",
    "y_test_svc = clfSVC.predict(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*53)\n",
    "print('Random Forest with non-optimal gridCV parameters')\n",
    "print('-'*53)\n",
    "print(classification_report(y_test, y_test_rfc))\n",
    "print('-'*53)\n",
    "print('Non- Optimized SVM ')\n",
    "print('-'*53)\n",
    "print(classification_report(y_test1,y_test_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the confusion matrix\n",
    "cm3 = pd.DataFrame(index = clfSVC.classes_, \n",
    "                   columns = clfSVC.classes_,\n",
    "                   data = confusion_matrix(y_test1, y_test_svc))\n",
    "cm3.columns.name = 'Actual'\n",
    "cm3.index.name = 'Predicted'\n",
    "cm3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine with SVMSMOTE is clearly giving best results for recall/precision for faulty sensors predictions. Even after applying grid seaarch, the randomForest and decision trees are not able to provide same level of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python(nlp_cpu)",
   "language": "python",
   "name": "nlp_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
