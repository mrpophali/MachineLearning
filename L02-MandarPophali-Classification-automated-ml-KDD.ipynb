{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/NotebookVM/tutorials/regression-part2-automated-ml.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Use automated machine learning to predict taxi fares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you use automated machine learning in Azure Machine Learning service to create a regression model to predict NYC taxi fare prices. This process accepts training data and configuration settings, and automatically iterates through combinations of different feature normalization/standardization methods, models, and hyperparameter settings to arrive at the best model.\n",
    "\n",
    "In this tutorial you learn the following tasks:\n",
    "\n",
    "* Download, transform, and clean data using Azure Open Datasets\n",
    "* Train an automated machine learning regression model\n",
    "* Calculate model accuracy\n",
    "\n",
    "If you donâ€™t have an Azure subscription, create a free account before you begin. Try the [free or paid version](https://aka.ms/AMLFree) of Azure Machine Learning service today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Complete the [setup tutorial](https://docs.microsoft.com/azure/machine-learning/service/tutorial-1st-experiment-sdk-setup) if you don't already have an Azure Machine Learning service workspace or notebook virtual machine.\n",
    "* After you complete the setup tutorial, open the **tutorials/regression-automated-ml.ipynb** notebook using the same notebook server.\n",
    "\n",
    "This tutorial is also available on [GitHub](https://github.com/Azure/MachineLearningNotebooks/tree/master/tutorials) if you wish to run it in your own [local environment](https://docs.microsoft.com/azure/machine-learning/service/how-to-configure-environment#local). Run `pip install azureml-sdk[automl] azureml-opendatasets azureml-widgets` to get the required packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary packages. The Open Datasets package contains a class representing each data source (`NycTlcGreen` for example) to easily filter date parameters before downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.opendatasets import NycTlcGreen\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by creating a dataframe to hold the taxi data. When working in a non-Spark environment, Open Datasets only allows downloading one month of data at a time with certain classes to avoid `MemoryError` with large datasets. To download taxi data, iteratively fetch one month at a time, and before appending it to `green_taxi_df` randomly sample 2,000 records from each month to avoid bloating the dataframe. Then preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97298</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>0</td>\n",
       "      <td>2072</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97299</th>\n",
       "      <td>31</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>SF</td>\n",
       "      <td>2402</td>\n",
       "      <td>3814</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97300</th>\n",
       "      <td>33</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>SF</td>\n",
       "      <td>2402</td>\n",
       "      <td>3815</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97301</th>\n",
       "      <td>162</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>SF</td>\n",
       "      <td>1567</td>\n",
       "      <td>2738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97302</th>\n",
       "      <td>127</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>SF</td>\n",
       "      <td>1567</td>\n",
       "      <td>2736</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97303</th>\n",
       "      <td>321</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>RSTO</td>\n",
       "      <td>1506</td>\n",
       "      <td>1887</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97304</th>\n",
       "      <td>45</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>SF</td>\n",
       "      <td>2336</td>\n",
       "      <td>4201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97305</th>\n",
       "      <td>176</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>SF</td>\n",
       "      <td>1559</td>\n",
       "      <td>2732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97306</th>\n",
       "      <td>61</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>SF</td>\n",
       "      <td>2336</td>\n",
       "      <td>4194</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97307</th>\n",
       "      <td>47</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>SF</td>\n",
       "      <td>2402</td>\n",
       "      <td>3816</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration protocol_type   service  flag  src_bytes  dst_bytes  land  \\\n",
       "97298         0           tcp  ftp_data    SF          0       2072     0   \n",
       "97299        31           tcp    telnet    SF       2402       3814     0   \n",
       "97300        33           tcp    telnet    SF       2402       3815     0   \n",
       "97301       162           tcp    telnet    SF       1567       2738     0   \n",
       "97302       127           tcp    telnet    SF       1567       2736     0   \n",
       "97303       321           tcp    telnet  RSTO       1506       1887     0   \n",
       "97304        45           tcp    telnet    SF       2336       4201     0   \n",
       "97305       176           tcp    telnet    SF       1559       2732     0   \n",
       "97306        61           tcp    telnet    SF       2336       4194     0   \n",
       "97307        47           tcp    telnet    SF       2402       3816     0   \n",
       "\n",
       "       wrong_fragment  urgent  hot  ...    dst_host_srv_count  \\\n",
       "97298               0       0    1  ...                    84   \n",
       "97299               0       0    3  ...                     2   \n",
       "97300               0       0    3  ...                     3   \n",
       "97301               0       0    3  ...                     4   \n",
       "97302               0       0    1  ...                     5   \n",
       "97303               0       0    0  ...                     6   \n",
       "97304               0       0    3  ...                     7   \n",
       "97305               0       0    3  ...                     8   \n",
       "97306               0       0    3  ...                     9   \n",
       "97307               0       0    3  ...                    10   \n",
       "\n",
       "       dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "97298                    1.00                    0.00   \n",
       "97299                    1.00                    0.00   \n",
       "97300                    1.00                    0.00   \n",
       "97301                    1.00                    0.00   \n",
       "97302                    1.00                    0.00   \n",
       "97303                    1.00                    0.00   \n",
       "97304                    1.00                    0.00   \n",
       "97305                    1.00                    0.00   \n",
       "97306                    1.00                    0.00   \n",
       "97307                    1.00                    0.00   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "97298                         1.00                         0.02   \n",
       "97299                         0.50                         0.00   \n",
       "97300                         0.33                         0.00   \n",
       "97301                         0.25                         0.00   \n",
       "97302                         0.20                         0.00   \n",
       "97303                         0.17                         0.00   \n",
       "97304                         0.14                         0.00   \n",
       "97305                         0.12                         0.00   \n",
       "97306                         0.11                         0.00   \n",
       "97307                         0.10                         0.00   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "97298                  0.00                      0.00                  0.00   \n",
       "97299                  0.00                      0.00                  0.00   \n",
       "97300                  0.00                      0.00                  0.00   \n",
       "97301                  0.00                      0.00                  0.00   \n",
       "97302                  0.00                      0.00                  0.00   \n",
       "97303                  0.00                      0.00                  0.17   \n",
       "97304                  0.00                      0.00                  0.14   \n",
       "97305                  0.00                      0.00                  0.12   \n",
       "97306                  0.00                      0.00                  0.11   \n",
       "97307                  0.00                      0.00                  0.10   \n",
       "\n",
       "       dst_host_srv_rerror_rate  Class  \n",
       "97298                      0.00      1  \n",
       "97299                      0.00      1  \n",
       "97300                      0.00      1  \n",
       "97301                      0.00      1  \n",
       "97302                      0.00      1  \n",
       "97303                      0.17      1  \n",
       "97304                      0.14      1  \n",
       "97305                      0.12      1  \n",
       "97306                      0.11      1  \n",
       "97307                      0.10      1  \n",
       "\n",
       "[10 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load dataset \n",
    "kdd_df = pd.read_csv(\"https://library.startlearninglabs.uw.edu/DATASCI420/2019/Datasets/Intrusion%20Detection.csv\")\n",
    "kdd_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>...</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "      <td>97308.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>216.62</td>\n",
       "      <td>1.18</td>\n",
       "      <td>10.74</td>\n",
       "      <td>7.61</td>\n",
       "      <td>1157.12</td>\n",
       "      <td>3385.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>202.01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1359.01</td>\n",
       "      <td>0.42</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1.61</td>\n",
       "      <td>34220.86</td>\n",
       "      <td>37573.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.86</td>\n",
       "      <td>...</td>\n",
       "      <td>86.97</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>147.00</td>\n",
       "      <td>136.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>170.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>231.00</td>\n",
       "      <td>421.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>255.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>313.00</td>\n",
       "      <td>2124.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>255.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>58329.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>2194619.00</td>\n",
       "      <td>5134218.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>...</td>\n",
       "      <td>255.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration  protocol_type  service     flag  src_bytes  dst_bytes  \\\n",
       "count  97308.00       97308.00 97308.00 97308.00   97308.00   97308.00   \n",
       "mean     216.62           1.18    10.74     7.61    1157.12    3385.56   \n",
       "std     1359.01           0.42     3.12     1.61   34220.86   37573.05   \n",
       "min        0.00           0.00     0.00     0.00       0.00       0.00   \n",
       "25%        0.00           1.00    10.00     8.00     147.00     136.00   \n",
       "50%        0.00           1.00    10.00     8.00     231.00     421.00   \n",
       "75%        0.00           1.00    10.00     8.00     313.00    2124.00   \n",
       "max    58329.00           2.00    24.00     8.00 2194619.00 5134218.00   \n",
       "\n",
       "          land  wrong_fragment   urgent      hot   ...     dst_host_srv_count  \\\n",
       "count 97308.00        97308.00 97308.00 97308.00   ...               97308.00   \n",
       "mean      0.00            0.00     0.00     0.05   ...                 202.01   \n",
       "std       0.00            0.00     0.01     0.86   ...                  86.97   \n",
       "min       0.00            0.00     0.00     0.00   ...                   0.00   \n",
       "25%       0.00            0.00     0.00     0.00   ...                 170.00   \n",
       "50%       0.00            0.00     0.00     0.00   ...                 255.00   \n",
       "75%       0.00            0.00     0.00     0.00   ...                 255.00   \n",
       "max       1.00            0.00     3.00    30.00   ...                 255.00   \n",
       "\n",
       "       dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count                97308.00                97308.00   \n",
       "mean                     0.85                    0.06   \n",
       "std                      0.31                    0.18   \n",
       "min                      0.00                    0.00   \n",
       "25%                      0.91                    0.00   \n",
       "50%                      1.00                    0.00   \n",
       "75%                      1.00                    0.01   \n",
       "max                      1.00                    1.00   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                     97308.00                     97308.00   \n",
       "mean                          0.13                         0.02   \n",
       "std                           0.28                         0.05   \n",
       "min                           0.00                         0.00   \n",
       "25%                           0.00                         0.00   \n",
       "50%                           0.01                         0.01   \n",
       "75%                           0.07                         0.03   \n",
       "max                           1.00                         1.00   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count              97308.00                  97308.00              97308.00   \n",
       "mean                   0.00                      0.00                  0.06   \n",
       "std                    0.03                      0.02                  0.22   \n",
       "min                    0.00                      0.00                  0.00   \n",
       "25%                    0.00                      0.00                  0.00   \n",
       "50%                    0.00                      0.00                  0.00   \n",
       "75%                    0.00                      0.00                  0.00   \n",
       "max                    1.00                      1.00                  1.00   \n",
       "\n",
       "       dst_host_srv_rerror_rate    Class  \n",
       "count                  97308.00 97308.00  \n",
       "mean                       0.06     0.00  \n",
       "std                        0.22     0.02  \n",
       "min                        0.00     0.00  \n",
       "25%                        0.00     0.00  \n",
       "50%                        0.00     0.00  \n",
       "75%                        0.00     0.00  \n",
       "max                        1.00     1.00  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using label encoder, convert 3 features to numberic\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "kdd_df['protocol_type'] = le.fit_transform(kdd_df['protocol_type'])\n",
    "kdd_df['service'] = le.fit_transform(kdd_df['service'])\n",
    "kdd_df['flag'] = le.fit_transform(kdd_df['flag'])\n",
    "kdd_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove zero value columns and lets plot box plots for rest of the columns\n",
    "kdd_df_new = kdd_df.drop(['is_host_login','wrong_fragment','num_outbound_cmds'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert new dataframe into output label \"Y\" and input features X\n",
    "X = kdd_df_new.iloc[:,:38]\n",
    "Y = kdd_df_new.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and test.The same splits i will use across various classifiers below\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,random_state=34,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "#scale the train/test data using MinMaxScaler. Same scaler is used across all classifiers for consistency \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure workspace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a workspace object from the existing workspace. A [Workspace](https://docs.microsoft.com/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py) is a class that accepts your Azure subscription and resource information. It also creates a cloud resource to monitor and track your model runs. `Workspace.from_config()` reads the file **config.json** and loads the authentication details into an object named `ws`. `ws` is used throughout the rest of the code in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the experiment parameter and model settings for training. View the full list of [settings](https://docs.microsoft.com/azure/machine-learning/service/how-to-configure-auto-train). Submitting the experiment with these default settings will take approximately 5-10 min, but if you want a shorter run time, reduce the `iterations` parameter.\n",
    "\n",
    "\n",
    "|Property| Value in this tutorial |Description|\n",
    "|----|----|---|\n",
    "|**iteration_timeout_minutes**|2|Time limit in minutes for each iteration. Reduce this value to decrease total runtime.|\n",
    "|**iterations**|20|Number of iterations. In each iteration, a new machine learning model is trained with your data. This is the primary value that affects total run time.|\n",
    "|**primary_metric**| spearman_correlation | Metric that you want to optimize. The best-fit model will be chosen based on this metric.|\n",
    "|**preprocess**| True | By using **True**, the experiment can preprocess the input data (handling missing data, converting text to numeric, etc.)|\n",
    "|**verbosity**| logging.INFO | Controls the level of logging.|\n",
    "|**n_cross_validations**|5|Number of cross-validation splits to perform when validation data is not specified.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 2,\n",
    "    \"iterations\": 20,\n",
    "    \"primary_metric\": 'accuracy',\n",
    "    \"preprocess\": False,\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"n_cross_validations\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your defined training settings as a `**kwargs` parameter to an `AutoMLConfig` object. Additionally, specify your training data and the type of model, which is `regression` in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "automl_config = AutoMLConfig(task='classification',\n",
    "                             debug_log='automated_ml_errors.log',\n",
    "                             X=X_train_scaled,\n",
    "                             y=y_train.values.flatten(),\n",
    "                             **automl_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated machine learning pre-processing steps (feature normalization, handling missing data, converting text to numeric, etc.) become part of the underlying model. When using the model for predictions, the same pre-processing steps applied during training are applied to your input data automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the automatic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an experiment object in your workspace. An experiment acts as a container for your individual runs. Pass the defined `automl_config` object to the experiment, and set the output to `True` to view progress during the run. \n",
    "\n",
    "After starting the experiment, the output shown updates live as the experiment runs. For each iteration, you see the model type, the run duration, and the training accuracy. The field `BEST` tracks the best running training score based on your metric type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_bb55fe6a-96f8-4e1a-b554-209ee61b6c9d\n",
      "Current status: DatasetCrossValidationSplit. Generating CV splits.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MinMaxScaler SGD                               0:00:12       0.9998    0.9998\n",
      "         1   MinMaxScaler SGD                               0:00:13       0.9936    0.9998\n",
      "         2   StandardScalerWrapper SGD                      0:00:12       0.9997    0.9998\n",
      "         3   StandardScalerWrapper SGD                      0:00:13       0.9996    0.9998\n",
      "         4   MinMaxScaler SGD                               0:00:12       0.9997    0.9998\n",
      "         5   MinMaxScaler RandomForest                      0:00:16       0.9984    0.9998\n",
      "         6   StandardScalerWrapper ExtremeRandomTrees       0:00:14       0.9667    0.9998\n",
      "         7   MinMaxScaler SGD                               0:00:12       0.9997    0.9998\n",
      "         8   StandardScalerWrapper SGD                      0:00:12       0.5294    0.9998\n",
      "         9   StandardScalerWrapper RandomForest             0:00:13       0.9738    0.9998\n",
      "        10   StandardScalerWrapper RandomForest             0:00:12       0.9308    0.9998\n",
      "        11   StandardScalerWrapper SGD                      0:00:12       0.9965    0.9998\n",
      "        12   StandardScalerWrapper ExtremeRandomTrees       0:00:15       0.9997    0.9998\n",
      "        13   MinMaxScaler RandomForest                      0:00:18       0.9800    0.9998\n",
      "        14   MinMaxScaler ExtremeRandomTrees                0:00:12       0.9997    0.9998\n",
      "        15   MinMaxScaler BernoulliNaiveBayes               0:00:12       0.9846    0.9998\n",
      "        16   StandardScalerWrapper BernoulliNaiveBayes      0:00:13       0.9970    0.9998\n",
      "        17   MinMaxScaler RandomForest                      0:00:15       0.9563    0.9998\n",
      "        18   VotingEnsemble                                 0:00:25       0.9999    0.9999\n",
      "        19   StackEnsemble                                  0:00:25       0.9998    0.9999\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "experiment = Experiment(ws, \"KDD-experiment\")\n",
    "local_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the results of automatic training with a [Jupyter widget](https://docs.microsoft.com/python/api/azureml-widgets/azureml.widgets?view=azure-ml-py). The widget allows you to see a graph and table of all individual run iterations, along with training accuracy metrics and metadata. Additionally, you can filter on different accuracy metrics than your primary metric with the dropdown selector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41a1c3fe09d46bd84e0546b1e38c07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(local_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the best model from your iterations. The `get_output` function returns the best run and the fitted model for the last fit invocation. By using the overloads on `get_output`, you can retrieve the best run and fitted model for any logged metric or a particular iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: KDD-experiment,\n",
      "Id: AutoML_bb55fe6a-96f8-4e1a-b554-209ee61b6c9d_18,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n",
      "               estimators=[('0', Pipeline(memory=None,\n",
      "     steps=[('MinMaxScaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('SGDClassifierWrapper', SGDClassifierWrapper(alpha=0.816418367346938...666666666667, 0.13333333333333333, 0.06666666666666667, 0.26666666666666666, 0.06666666666666667]))])\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = local_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the best model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.9998287260644675\n",
      "Train Score:  0.9999119136754019\n",
      "Confusion Matrix :\n",
      "[[29184     0]\n",
      " [    5     4]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     29184\n",
      "           1       1.00      0.44      0.62         9\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     29193\n",
      "   macro avg       1.00      0.72      0.81     29193\n",
      "weighted avg       1.00      1.00      1.00     29193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predict values using test data\n",
    "\n",
    "predict = fitted_model.predict(X_test_scaled)\n",
    "testscore = fitted_model.score(X_test_scaled,y_test)\n",
    "#score test values \n",
    "print(\"Test Score: \",testscore)\n",
    "#score train values\n",
    "print(\"Train Score: \", fitted_model.score(X_train_scaled,y_train))\n",
    "from sklearn.metrics import confusion_matrix,recall_score,precision_score\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y_test,predict))\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/62/08c14224a7e242df2cef7b312d2ef821c3931ec9b015ff93bb52ec8a10a3/imbalanced_learn-0.5.0-py3-none-any.whl (173kB)\n",
      "\u001b[K     |████████████████████████████████| 174kB 6.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (0.13.2)\n",
      "Collecting scikit-learn>=0.21 (from imbalanced-learn->imblearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7MB 38.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.17 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "\u001b[31mERROR: azureml-train-automl 1.0.62 has requirement scikit-learn<=0.20.3,>=0.19.0, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-train-automl 1.0.62 has requirement wheel==0.30.0, but you'll have wheel 0.29.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-automl-core 1.0.62 has requirement scikit-learn<=0.20.3,>=0.19.0, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-automl-core 1.0.62 has requirement wheel==0.30.0, but you'll have wheel 0.29.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: scikit-learn, imbalanced-learn, imblearn\n",
      "  Found existing installation: scikit-learn 0.20.3\n",
      "    Uninstalling scikit-learn-0.20.3:\n",
      "      Successfully uninstalled scikit-learn-0.20.3\n",
      "Successfully installed imbalanced-learn-0.5.0 imblearn-0.0 scikit-learn-0.21.3\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install --upgrade imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import SMOTE\n",
    "# I am using not Majority to allow expand minority class (bad ones) to expand\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# create a SMOTE object\n",
    "sm = SMOTE(sampling_strategy='not majority',random_state=1)\n",
    "# use SMOTE to fit the data in X and y\n",
    "X_res, y_res = sm.fit_sample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train_res and test_res.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_res,X_test_res,y_train_res,y_test_res = train_test_split(X_res,y_res,random_state=34,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the train/test data using RobustScaler\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled_res = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled_res = scaler.transform(X_test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\": 2,\n",
    "    \"iterations\": 20,\n",
    "    \"primary_metric\": 'accuracy',\n",
    "    \"preprocess\": False,\n",
    "    \"verbosity\": logging.INFO,\n",
    "    \"n_cross_validations\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "automl_config = AutoMLConfig(task='classification',\n",
    "                             debug_log='automated_ml_errors.log',\n",
    "                             X=X_train_scaled_res,\n",
    "                             y=y_train_res.flatten(),\n",
    "                             **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_f1eed1b5-52bc-4ce9-8e9f-5acd76aad5a1\n",
      "Current status: DatasetCrossValidationSplit. Generating CV splits.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MinMaxScaler SGD                               0:00:13       0.9993    0.9993\n",
      "         1   MinMaxScaler SGD                               0:00:13       0.9983    0.9993\n",
      "         2   StandardScalerWrapper SGD                      0:00:14       0.9991    0.9993\n",
      "         3   StandardScalerWrapper SGD                      0:00:13       0.9996    0.9996\n",
      "         4   MinMaxScaler SGD                               0:00:14       0.9991    0.9996\n",
      "         5   MinMaxScaler RandomForest                      0:00:18       0.9996    0.9996\n",
      "         6   StandardScalerWrapper ExtremeRandomTrees       0:00:15       0.9798    0.9996\n",
      "         7   MinMaxScaler SGD                               0:00:15       0.9992    0.9996\n",
      "         8   StandardScalerWrapper SGD                      0:00:15       0.9973    0.9996\n",
      "         9   StandardScalerWrapper RandomForest             0:00:20       0.9974    0.9996\n",
      "        10   StandardScalerWrapper RandomForest             0:00:18       0.9899    0.9996\n",
      "        11   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/azureml_py36/lib/python3.6/logging/handlers.py\", line 72, in emit\n",
      "    self.doRollover()\n",
      "  File \"/anaconda/envs/azureml_py36/lib/python3.6/logging/handlers.py\", line 169, in doRollover\n",
      "    os.rename(sfn, dfn)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/mnt/azmnt/code/Users/manpo/samples-1.0.65/tutorials/automated_ml_errors.log.6' -> '/mnt/azmnt/code/Users/manpo/samples-1.0.65/tutorials/automated_ml_errors.log.7'\n",
      "Call stack:\n",
      "  File \"/anaconda/envs/azureml_py36/lib/python3.6/threading.py\", line 884, in _bootstrap\n",
      "    self._bootstrap_inner()\n",
      "  File \"/anaconda/envs/azureml_py36/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/anaconda/envs/azureml_py36/lib/python3.6/threading.py\", line 1182, in run\n",
      "    self.function(*self.args, **self.kwargs)\n",
      "  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/automl/core/timer_utilities.py\", line 40, in _run\n",
      "    self.callback(*self.args, **self.kwargs)\n",
      "  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/automl/core/systemusage_telemetry.py\", line 170, in _get_usage\n",
      "    '{}child '.format(prefix_message))\n",
      "  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/automl/core/systemusage_telemetry.py\", line 67, in _log_cpu_usage\n",
      "    self.logger.info(\"{}cpu time {}\".format(prefix_message, cpu_time), extra=extra_info)\n",
      "  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/automl/core/_vendor/automl/client/core/common/activity_logger.py\", line 225, in info\n",
      "    self.log(logging.INFO, msg, *args, **kwargs)\n",
      "  File \"/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/automl/core/_vendor/automl/client/core/common/activity_logger.py\", line 199, in log\n",
      "    self._logger.log(level, msg, extra=extra, *args, **kwargs)\n",
      "Message: 'child cpu time 1386.811563'\n",
      "Arguments: ()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScalerWrapper SGD                      0:00:14       0.9989    0.9996\n",
      "        12   StandardScalerWrapper ExtremeRandomTrees       0:00:20       0.9968    0.9996\n",
      "        13   MinMaxScaler RandomForest                      0:00:36       0.9973    0.9996\n",
      "        14   MinMaxScaler ExtremeRandomTrees                0:00:15       0.9897    0.9996\n",
      "        15   MinMaxScaler BernoulliNaiveBayes               0:00:14       0.9959    0.9996\n",
      "        16   StandardScalerWrapper BernoulliNaiveBayes      0:00:13       0.9962    0.9996\n",
      "        17   MinMaxScaler RandomForest                      0:00:20       0.9956    0.9996\n",
      "        18   VotingEnsemble                                 0:00:28       0.9997    0.9997\n",
      "        19   StackEnsemble                                  0:00:47       0.9994    0.9997\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "experiment = Experiment(ws, \"KDD-experiment_SMOTE\")\n",
    "local_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30286d8f95b94b69af81ca3b8bea219e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(local_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: KDD-experiment_SMOTE,\n",
      "Id: AutoML_f1eed1b5-52bc-4ce9-8e9f-5acd76aad5a1_18,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n",
      "               estimators=[('5', Pipeline(memory=None,\n",
      "     steps=[('MinMaxScaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ('RandomForestClassifier', RandomForestClassifier(bootstrap=True, cla...333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333]))])\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = local_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.9995374098377507\n",
      "Train Score:  0.9997503469443201\n",
      "Confusion Matrix :\n",
      "[[29451    27]\n",
      " [    0 28889]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     29478\n",
      "           1       1.00      1.00      1.00     28889\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     58367\n",
      "   macro avg       1.00      1.00      1.00     58367\n",
      "weighted avg       1.00      1.00      1.00     58367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predict values using test data\n",
    "\n",
    "predict = fitted_model.predict(X_test_scaled_res)\n",
    "testscore = fitted_model.score(X_test_scaled_res,y_test_res)\n",
    "#score test values \n",
    "print(\"Test Score: \",testscore)\n",
    "#score train values\n",
    "print(\"Train Score: \", fitted_model.score(X_train_scaled_res,y_train_res))\n",
    "from sklearn.metrics import confusion_matrix,recall_score,precision_score\n",
    "print(\"Confusion Matrix :\")\n",
    "print(confusion_matrix(y_test_res,predict))\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test_res, predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "jeffshep"
   }
  ],
  "categories": [
   "tutorials"
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "msauthor": "trbye"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
